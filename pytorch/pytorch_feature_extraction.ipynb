{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 提取VGG16卷积层的特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# @Author:Liu Chuanlong\n",
    "import torch.utils.data as data\n",
    "import os\n",
    "from torchvision.models import vgg16\n",
    "from INSTRE import INSTREclassification as INCLS\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import torchvision.transforms as transforms\n",
    "import time\n",
    "\n",
    "class Warp(object):\n",
    "    def __init__(self, size, interpolation=Image.BILINEAR):\n",
    "        self.size = int(size)\n",
    "        self.interpolation = interpolation\n",
    "\n",
    "    def __call__(self, img):\n",
    "        return img.resize((self.size, self.size), self.interpolation)\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.__class__.__name__ + ' (size={size}, interpolation={interpolation})'.format(size=self.size,interpolation=self.interpolation)\n",
    "                \n",
    "def extract_feature(model, inputs):\n",
    "    model.fc = torch.nn.LeakyReLU(0.1)\n",
    "    model.eval()\n",
    "\n",
    "    result = model(inputs)\n",
    "    result_npy = result.data.numpy()\n",
    "    \n",
    "    return result_npy[0]\n",
    "\n",
    "def get_features(pretrained_model,inputs):\n",
    " \n",
    "    net1 = nn.Sequential(*list(pretrained_model.children())[0])\n",
    "    out1 = net1(inputs)\n",
    "    return out1\n",
    "\n",
    "train_dataset = INCLS('/home/liuchuanloong/amy/deep_retrieval', 'train', transforms.Compose([\n",
    "                Warp(224),\n",
    "                # transforms.ToTensor(),\n",
    "                # transforms.Scale(224),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                lambda x: torch.from_numpy(np.array(x)).permute(2, 0, 1).float(),\n",
    "                lambda x: x.index_select(0, torch.LongTensor([2,1,0]))]))\n",
    "\n",
    "val_dataset = INCLS('/home/liuchuanloong/amy/deep_retrieval', 'test',transforms.Compose([\n",
    "                Warp(224),\n",
    "                # transforms.ToTensor(),\n",
    "                # transforms.Scale(224),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                lambda x: torch.from_numpy(np.array(x)).permute(2, 0, 1).float(),\n",
    "                lambda x: x.index_select(0, torch.LongTensor([2,1,0]))]))\n",
    "\n",
    "# data loader\n",
    "train_loader = data.DataLoader(train_dataset, batch_size=32, shuffle=True,\n",
    "                                           num_workers=2)\n",
    "val_loader = data.DataLoader(val_dataset, batch_size=32, shuffle=False,\n",
    "                                          num_workers=2)\n",
    "\n",
    "print('start!!!')\n",
    "start = time.time()\n",
    "VGG16 = vgg16(pretrained=True).cuda()\n",
    "time_elapse = time.time() - start\n",
    "print('transform to cuda done!!! elapse{}s'.format(time_elapse))\n",
    "\n",
    "for step, (b_x,b_y) in enumerate(train_loader):  \n",
    "    inputs = torch.autograd.Variable(b_x[0]).cuda()\n",
    "    print(get_features(VGG16,inputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# resnet18 模型特征提取测试 两种方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torch.autograd import Variable\n",
    " \n",
    "import time\n",
    " \n",
    "class toyNet(nn.Module):\n",
    " \n",
    "    def __init__(self, pretrained_model, layers):\n",
    "        super(toyNet, self).__init__()\n",
    "\n",
    "\n",
    "        self.net1 = nn.Sequential(*list(pretrained_model.children())[:layers[0]])\n",
    "        self.net2 = nn.Sequential(*list(pretrained_model.children())[layers[0]:layers[1]])\n",
    "        self.net3 = nn.Sequential(*list(pretrained_model.children())[layers[1]:layers[2]])\n",
    "\n",
    " \n",
    "    def forward(self, x):\n",
    "\n",
    "        out1 = self.net1(x)\n",
    "        out2 = self.net2(out1)\n",
    "        out3 = self.net3(out2)\n",
    "\n",
    "        return out1, out2, out3\n",
    "\n",
    "def get_features(pretrained_model, x, layers = [3, 4, 7]):\n",
    " \n",
    "    net1 = nn.Sequential(*list(pretrained_model.children())[:layers[0]])\n",
    "#     print(net1)\n",
    "    out1 = net1(x)\n",
    "\n",
    "    net2 = nn.Sequential(*list(pretrained_model.children())[layers[0]:layers[1]])\n",
    "#     print(net2)\n",
    "    out2 = net2(out1)\n",
    "\n",
    "    net3 = nn.Sequential(*list(pretrained_model.children())[layers[1]:layers[2]])\n",
    "#     print(net3)\n",
    "    out3 = net3(out2)\n",
    "\n",
    "    return out1, out2, out3\n",
    " \n",
    "x = Variable(torch.rand(1,3,224,224))\n",
    "net = models.resnet18(pretrained=True)\n",
    " \n",
    "if torch.cuda.is_available():\n",
    "    x = x.cuda()\n",
    "    net = net.cuda()\n",
    "\n",
    "start = time.time()\n",
    " \n",
    "o1, o2, o3 = get_features(net, x)\n",
    " \n",
    "print(time.time() - start)\n",
    " \n",
    "print(o1.data.size())\n",
    "print(o2.data.size())\n",
    "print(o3.data.size())\n",
    " \n",
    "print('----------------------------------------------')\n",
    " \n",
    "start = time.time()\n",
    " \n",
    "toynet = toyNet(net, [3,4,7])\n",
    "y1, y2, y3 = toynet(x)\n",
    " \n",
    "print(time.time() - start)\n",
    " \n",
    "print(y1.data.size())\n",
    "print(y2.data.size())\n",
    "print(y3.data.size())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG16  提取某一层的特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import models\n",
    "from torch.autograd import Variable\n",
    "import torchvision.transforms as transforms\n",
    " \n",
    "class CNNShow():\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        self.model.eval()\n",
    " \n",
    "        self.created_image = self.image_for_pytorch(np.uint8(np.random.uniform(150, 180, (224, 224, 3))))\n",
    " \n",
    " \n",
    "    def show(self):\n",
    "        x = self.created_image\n",
    "        for index, layer in enumerate(self.model):\n",
    "            print(index,layer)\n",
    "            x = layer(x)\n",
    "            print(x)\n",
    " \n",
    "    def image_for_pytorch(self,Data):\n",
    "        transform = transforms.Compose([\n",
    "            transforms.ToTensor(),  # range [0, 255] -> [0.0,1.0]\n",
    "            transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
    "        ]\n",
    "        )\n",
    "        imData = transform(Data)\n",
    "        imData = Variable(torch.unsqueeze(imData, dim=0), requires_grad=True)\n",
    "        return imData\n",
    "if __name__ == '__main__':\n",
    " \n",
    "    pretrained_model = models.vgg16(pretrained=True).features\n",
    "    CNN = CNNShow(pretrained_model)\n",
    "    CNN.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG16 分类网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# @Author:Liu Chuanlong\n",
    "import torch.utils.data as data\n",
    "import os\n",
    "from torchvision.models import vgg16\n",
    "from INSTRE import INSTREclassification as  INCLS\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "class Warp(object):\n",
    "    def __init__(self, size, interpolation=Image.BILINEAR):\n",
    "        self.size = int(size)\n",
    "        self.interpolation = interpolation\n",
    "\n",
    "    def __call__(self, img):\n",
    "        return img.resize((self.size, self.size), self.interpolation)\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.__class__.__name__ + ' (size={size}, interpolation={interpolation})'.format(size=self.size,interpolation=self.interpolation)\n",
    "\n",
    "train_dataset = INCLS('/home/liuchuanloong/amy/deep_retrieval', 'train', transforms.Compose([\n",
    "                Warp(224),\n",
    "                # transforms.ToTensor(),\n",
    "                # transforms.Scale(224),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                lambda x: torch.from_numpy(np.array(x)).permute(2, 0, 1).float(),\n",
    "                lambda x: x.index_select(0, torch.LongTensor([2,1,0]))]))\n",
    "val_dataset = INCLS('/home/liuchuanloong/amy/deep_retrieval', 'test',transforms.Compose([\n",
    "                Warp(224),\n",
    "                # transforms.ToTensor(),\n",
    "                # transforms.Scale(224),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                lambda x: torch.from_numpy(np.array(x)).permute(2, 0, 1).float(),\n",
    "                lambda x: x.index_select(0, torch.LongTensor([2,1,0]))]))\n",
    "\n",
    "# train_data = generatedata(train_dataset)\n",
    "\n",
    "# data loader\n",
    "train_loader = data.DataLoader(train_dataset, batch_size=32, shuffle=True,\n",
    "                                           num_workers=2)\n",
    "val_loader = data.DataLoader(val_dataset, batch_size=32, shuffle=False,\n",
    "                                          num_workers=2)\n",
    "print('start load model!!!')\n",
    "VGG16 = vgg16(pretrained=False)\n",
    "VGG16.cuda()\n",
    "print(VGG16)\n",
    "print('transfered to cuda done!!!')\n",
    "optimizer = torch.optim.Adam(VGG16.parameters(), lr= 0.1)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "EPOCH = 1\n",
    "for epoch in range(EPOCH):\n",
    "    for step, (b_x,b_y) in enumerate(train_loader):  # 分配 batch data, normalize x when iterate train_loader\n",
    "        b_y = torch.max(b_y,1)\n",
    "        print('b_x{}'.format(type(b_x[0])))\n",
    "        b_y = b_y[1].type(torch.LongTensor)\n",
    "        print('b_y{}'.format(type(b_y)))\n",
    "        input = torch.autograd.Variable(b_x[0]).cuda()\n",
    "        target = torch.autograd.Variable(b_y).cuda()\n",
    "        output = VGG16(input)  # VGG16 output\n",
    "        loss = loss_func(output, target).cpu()  # cross entropy loss\n",
    "        print(loss)\n",
    "        optimizer.zero_grad()  # clear gradients for this training step\n",
    "        loss.backward()  # backpropagation, compute gradients\n",
    "        optimizer.step()  # apply gradients"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
