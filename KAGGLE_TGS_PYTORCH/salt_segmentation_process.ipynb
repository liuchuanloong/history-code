{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 先选几张图片显示看看"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib  import pyplot as plt\n",
    "import matplotlib.image as mping\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ids= ['1f1cc6b3a4','5b7c160d0d','6c40978ddf','7dfdf6eeb8','7e5a6e5013']\n",
    "plt.figure(figsize=(20,10))\n",
    "for j, img_name in enumerate(ids):\n",
    "    q = j+1\n",
    "    img = cv2.imread('./saltdata/train/images/' + img_name + '.png')\n",
    "    img_mask = cv2.imread('./saltdata/train/masks/' + '5b7c160d0d' + '.png')\n",
    "    \n",
    "    plt.subplot(1,2*(1+len(ids)),q*2-1)\n",
    "    plt.imshow(img)\n",
    "    plt.subplot(1,2*(1+len(ids)),q*2)\n",
    "    plt.imshow(img_mask)\n",
    "plt.show()\n",
    "#图片的像素值都比较大，所以表现为黑色\n",
    "print(np.int32(np.bools(img_mask[0:100,0:100,0])))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_path = \"./data/train/images/5b7c160d0d.png\"\n",
    "image = np.array(cv2.imread(image_path),dtype=np.float32)\n",
    "mask = np.array(cv2.imread('./data/train/masks/5b7c160d0d.png'))\n",
    "#print(image[:,:,0])\n",
    "plt.imshow(image[:,:,0],cmap='gray')\n",
    "plt.figure()\n",
    "plt.imshow(mask)\n",
    "print((image[:,:,0]==image[:,:,1]))\n",
    "plt.figure()\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 将图片读入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "def load_img(path):\n",
    "    return cv2.imread(path)\n",
    "def get_ids(csv_path):\n",
    "    #list_id中保存的是训练图片的名称，但是没有后缀\n",
    "    df = pd.read_csv(csv_path)\n",
    "    list_id = []\n",
    "    for i,item in df.iterrows():\n",
    "        list_id.append(item[0]+\".png\")\n",
    "    return list_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from tqdm import tqdm_notebook\n",
    "import numpy as np\n",
    "path_train = \"./saltdata/train/\"\n",
    "path_test = \"./saltdata/test/\"\n",
    "im_height, im_width, im_chan = 128, 128, 1\n",
    "train_csv_path = \"./saltdata/train.csv\"\n",
    "test_csv_path = \"./saltdata/sample_submission.csv\"\n",
    "train_ids = get_ids(train_csv_path)\n",
    "test_ids = get_ids(test_csv_path)\n",
    "# Get and resize train images and masks\n",
    "X_train = np.zeros((len(train_ids), im_height, im_width, im_chan), dtype=np.float32)\n",
    "##此处的存为np.uint8值得商榷\n",
    "##需要做输入的标准化操作\n",
    "Y_train = np.zeros((len(train_ids), im_height, im_width, 1), dtype=np.bool)\n",
    "print('Getting and resizing train images and masks ... ')\n",
    "sys.stdout.flush()\n",
    "for n, id_ in tqdm_notebook(enumerate(train_ids), total=len(train_ids)):\n",
    "    path = path_train\n",
    "    img = load_img(path + '/images/' + id_)\n",
    "    x = cv2.resize(img,(128,128))#cv2.resize只能处理三个通道的图片\n",
    "    #x = resize(x, (128, 128, 1), mode='constant', preserve_range=True)#为什么只取一个通道投入网络训练？\n",
    "    #此处的resize是插值的方式，还是其他形式？\n",
    "    #可对比resize前后的图片\n",
    "    X_train[n] = np.expand_dims(np.array(x)[:,:,1],axis=-1)\n",
    "    mask = np.array(load_img(path + '/masks/' + id_))\n",
    "    mask = cv2.resize(mask, (128, 128))\n",
    "    Y_train[n] = np.expand_dims(np.array(mask[:,:,0]),axis = -1)\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 检查下训练的数据是否读入正确\n",
    "import random\n",
    "ix = random.randint(0, len(train_ids))\n",
    "plt.imshow(np.dstack((X_train[ix],X_train[ix],X_train[ix])))# 此处是对单通道的显示\n",
    "plt.show()\n",
    "tmp = np.squeeze(Y_train[ix]).astype(np.float32)\n",
    "plt.imshow(np.dstack((tmp,tmp,tmp)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define IoU metric\n",
    "from keras import backend as K\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D,Lambda,Conv2DTranspose\n",
    "from keras.models import Model\n",
    "import tensorflow as tf\n",
    "def mean_iou(y_true, y_pred):\n",
    "    prec = []\n",
    "    for t in np.arange(0.5, 1.0, 0.05):\n",
    "        y_pred_ = tf.to_int32(y_pred > t)\n",
    "        score, up_opt = tf.metrics.mean_iou(y_true, y_pred_, 2)\n",
    "        K.get_session().run(tf.local_variables_initializer())\n",
    "        with tf.control_dependencies([up_opt]):\n",
    "            score = tf.identity(score)\n",
    "        prec.append(score)\n",
    "    return K.mean(K.stack(prec), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Build U-Net model\n",
    "inputs = Input((im_height, im_width, im_chan))\n",
    "s = Lambda(lambda x: x / 255) (inputs)\n",
    "\n",
    "c1 = Conv2D(8, (3, 3), activation='relu', padding='same') (s)\n",
    "c1 = Conv2D(8, (3, 3), activation='relu', padding='same') (c1)\n",
    "p1 = MaxPooling2D((2, 2)) (c1)\n",
    "\n",
    "c2 = Conv2D(16, (3, 3), activation='relu', padding='same') (p1)\n",
    "c2 = Conv2D(16, (3, 3), activation='relu', padding='same') (c2)\n",
    "p2 = MaxPooling2D((2, 2)) (c2)\n",
    "\n",
    "c3 = Conv2D(32, (3, 3), activation='relu', padding='same') (p2)\n",
    "c3 = Conv2D(32, (3, 3), activation='relu', padding='same') (c3)\n",
    "p3 = MaxPooling2D((2, 2)) (c3)\n",
    "\n",
    "c4 = Conv2D(64, (3, 3), activation='relu', padding='same') (p3)\n",
    "c4 = Conv2D(64, (3, 3), activation='relu', padding='same') (c4)\n",
    "p4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n",
    "\n",
    "c5 = Conv2D(128, (3, 3), activation='relu', padding='same') (p4)\n",
    "c5 = Conv2D(128, (3, 3), activation='relu', padding='same') (c5)\n",
    "\n",
    "u6 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (c5)\n",
    "u6 = concatenate([u6, c4])\n",
    "c6 = Conv2D(64, (3, 3), activation='relu', padding='same') (u6)\n",
    "c6 = Conv2D(64, (3, 3), activation='relu', padding='same') (c6)\n",
    "\n",
    "u7 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c6)\n",
    "u7 = concatenate([u7, c3])\n",
    "c7 = Conv2D(32, (3, 3), activation='relu', padding='same') (u7)\n",
    "c7 = Conv2D(32, (3, 3), activation='relu', padding='same') (c7)\n",
    "\n",
    "u8 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c7)\n",
    "u8 = concatenate([u8, c2])\n",
    "c8 = Conv2D(16, (3, 3), activation='relu', padding='same') (u8)\n",
    "c8 = Conv2D(16, (3, 3), activation='relu', padding='same') (c8)\n",
    "\n",
    "u9 = Conv2DTranspose(8, (2, 2), strides=(2, 2), padding='same') (c8)\n",
    "u9 = concatenate([u9, c1], axis=3)\n",
    "c9 = Conv2D(8, (3, 3), activation='relu', padding='same') (u9)\n",
    "c9 = Conv2D(8, (3, 3), activation='relu', padding='same') (c9)\n",
    "\n",
    "outputs = Conv2D(1, (1, 1), activation='sigmoid') (c9)\n",
    "\n",
    "model = Model(inputs=[inputs], outputs=[outputs])\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[mean_iou])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping,ModelCheckpoint\n",
    "earlystopper = EarlyStopping(patience=5, verbose=1)\n",
    "checkpointer = ModelCheckpoint('tgs-salt_model.{epoch:03d}.hdf5', verbose=1, save_best_only=True)\n",
    "\n",
    "results = model.fit(X_train, Y_train, validation_split=0.1, batch_size=8, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights(\"model-tag-salt-1.h5\")\n",
    "ini_epoch = 0\n",
    "results = model.fit(X_train, Y_train, initial_epoch=ini_epoch, validation_split=0.1, batch_size=8, epochs=30, \n",
    "                    callbacks=[earlystopper, checkpointer])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### resize测试图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get and resize test images\n",
    "X_test = np.zeros((len(test_ids), im_height, im_width, im_chan), dtype=np.uint8)\n",
    "sizes_test = []\n",
    "print('Getting and resizing test images ... ')\n",
    "sys.stdout.flush()\n",
    "for n, id_ in tqdm_notebook(enumerate(test_ids), total=len(test_ids)):\n",
    "    path = path_test\n",
    "    img = load_img(path + '/images/' + id_)\n",
    "    x = np.array(img)[:,:,1]\n",
    "    sizes_test.append([x.shape[0], x.shape[1]])\n",
    "    #x = resize(x, (128, 128, 1), mode='constant', preserve_range=True)\n",
    "    x = cv2.resize(x,(128,128))\n",
    "    X_test[n] = np.expand_dims(np.array(x),axis=-1)\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 在训练集，验证集，测试集上做预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predict on train, val and test\n",
    "from keras.models import load_model\n",
    "model = load_model('model-tgs-salt-1.h5', custom_objects={'mean_iou': mean_iou})\n",
    "preds_train = model.predict(X_train[:int(X_train.shape[0]*0.9)], verbose=1)\n",
    "preds_val = model.predict(X_train[int(X_train.shape[0]*0.9):], verbose=1)\n",
    "preds_test = model.predict(X_test, verbose=1)\n",
    "\n",
    "# 设定阈值，得到预测的结果\n",
    "preds_train_t = (preds_train > 0.5).astype(np.uint8)\n",
    "preds_val_t = (preds_val > 0.5).astype(np.uint8)\n",
    "preds_test_t = (preds_test > 0.5).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 将得到的测试集预测图片进行反采样，从【128，,128】回到【101,101】大小"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create list of upsampled test masks\n",
    "preds_test_upsampled = []\n",
    "for i in range(len(preds_test)):\n",
    "    preds_test_upsampled.append(cv2.resize(np.squeeze(preds_test[i]), \n",
    "                                       (sizes_test[i][0], sizes_test[i][1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 确认是否从采样会原来大小"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds_test_upsampled[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 随便从训练集中选张样本，对比其mask 和prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Perform a sanity check on some random training samples\n",
    "ix = random.randint(0, len(preds_train_t))\n",
    "plt.imshow(np.dstack((X_train[ix],X_train[ix],X_train[ix])))\n",
    "plt.show()\n",
    "tmp = np.squeeze(Y_train[ix]).astype(np.float32)\n",
    "plt.imshow(np.dstack((tmp,tmp,tmp)))\n",
    "plt.show()\n",
    "tmp = np.squeeze(preds_train_t[ix]).astype(np.float32)\n",
    "plt.imshow(np.dstack((tmp,tmp,tmp)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 将mask转换成比赛需要提交的格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def RLenc(img, order='F', format=True):\n",
    "    \"\"\"\n",
    "    img is binary mask image, shape (r,c)\n",
    "    order is down-then-right, i.e. Fortran\n",
    "    format determines if the order needs to be preformatted (according to submission rules) or not\n",
    "\n",
    "    returns run length as an array or string (if format is True)\n",
    "    \"\"\"\n",
    "    bytes = img.reshape(img.shape[0] * img.shape[1], order=order)\n",
    "    runs = []  ## list of run lengths\n",
    "    r = 0  ## the current run length\n",
    "    pos = 1  ## count starts from 1 per WK\n",
    "    for c in bytes:\n",
    "        if (c == 0):\n",
    "            if r != 0:\n",
    "                runs.append((pos, r))\n",
    "                pos += r\n",
    "                r = 0\n",
    "            pos += 1\n",
    "        else:\n",
    "            r += 1\n",
    "\n",
    "    # if last run is unsaved (i.e. data ends with 1)\n",
    "    if r != 0:\n",
    "        runs.append((pos, r))\n",
    "        pos += r\n",
    "        r = 0\n",
    "\n",
    "    if format:\n",
    "        z = ''\n",
    "\n",
    "        for rr in runs:\n",
    "            z += '{} {} '.format(rr[0], rr[1])\n",
    "        return z[:-1]\n",
    "    else:\n",
    "        return runs\n",
    "\n",
    "#pred_dict = {fn[:-4]:RLenc(np.round(preds_test_upsampled[i])) for i,fn in tqdm_notebook(enumerate(test_ids))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_labels = np.zeros((4000,101,101),dtype=\"np.uint8\")\n",
    "for i, fn in enumerate(train_ids):\n",
    "    \n",
    "    raw_labels[i] = cv2.resize(np.dstack((Y_train[i],Y_train[i],Y_train[i])),(101,101))[:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_dict = {fn[:-4]:RLenc(np.round(cv2.resize(np.squeeze(Y_train[i]).astype(np.uint8),(101,101)))) for i,fn in tqdm_notebook(enumerate(train_ids))}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 写入csv文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub = pd.DataFrame.from_dict(pred_dict,orient='index')\n",
    "sub.index.names = ['id']\n",
    "sub.columns = ['rle_mask']\n",
    "sub.to_csv('self_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n = 5\n",
    "for i,fn in enumerate(train_ids[:n]):\n",
    "    plt.subplot(1,n*2,i+1)\n",
    "    plt.title(str(i))\n",
    "    plt.imshow(np.dstack((Y_train[i],Y_train[i],Y_train[i])).astype(np.float32))\n",
    "\n",
    "    \n",
    "plt.show()\n",
    "for i,fn in enumerate(train_ids[:n]):\n",
    "    raw = cv2.imread(\"./data/train/masks/\"+fn)\n",
    "    plt.subplot(1,n*2,i+2)\n",
    "    plt.title(str(i))\n",
    "    plt.imshow(raw)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(train_ids[2730])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#plt.imshow(np.squeeze(Y_train[2730],axis=-1))\n",
    "result = cv2.resize(np.dstack((Y_train[2730],Y_train[2730],Y_train[2730])).astype(np.float32),(101,101))\n",
    "plt.imshow(result)\n",
    "print(result.shape)\n",
    "plt.show()\n",
    "raw_msk = cv2.imread(\"0aab0afa9c.png\")\n",
    "plt.figure()\n",
    "plt.imshow(raw_msk)\n",
    "plt.show()\n",
    "plt.figure()\n",
    "plt.imshow(np.dstack((X_train[2730],X_train[2730],X_train[2730])))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.6",
   "language": "python",
   "name": "py3.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
